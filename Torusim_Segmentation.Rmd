---
title: "Aplicaciones del Aprendizaje Estadístico a la segmentación del mercado turístico"
author: "Llorenç B. Femenias"
date: "21/11/2019"
output: html_document
---

```{r global_options, include = FALSE, warning = FALSE}
knitr::opts_chunk$set(fig.width=5, fig.height=5,  fig.align="center", echo=TRUE, warning=FALSE, message=FALSE) 
rm(list=ls())
cat("\014") #limpia pantalla
library(tidyverse)
library(gbm)
library(MASS)
library(caTools)
library(caret)
library(ggvis)
library(class)
library(gmodels)
library(ggplot2)
library(foreign)
library(nnet)
library(tree)
library(randomForest)
```

# 1. Introducción y justificación

El turismo representa el 12.3% del PIB y el 12.7% del empleo total en España (INE, Cuenta satélite del turismo de España, 2019), siendo uno de los sectores claves en la economía del país. Como es de esperar en una industria con semejante relevancia, el uso de técnicas de aprendizaje estadístico, automático o minería de datos para mejorar la toma de decisiones en las empresas del sector está a la orden del día. 

Algunos ejemplos de estas aplicaciones están relacionadas con el análisis de la demanda turística (Law, Mok, & Goh, 2007), la aplicación de los análisis de Big Data para la generación de conocimiento de destinaciones turísticas (Fuchs, Höpken, & Lexhagen, 2014), la clasificación de “sentimientos” en las “reviews” de las destinaciones turísticas (Ye, Zhang, & Law, 2009), entre muchos otros casos.

Entre estos campos de aplicación destaca el de la segmentación de mercado. La segmentación de mercado (por motivación, por actividades a realizar, por presupuesto disponible, …) constituye una herramienta fundamental a la hora de gestionar destinaciones y empresas (p.e: establecimientos hoteleros) turísticas, principalmente por el impacto que tiene en términos de márqueting (Dolnicar, 2008; Tkaczynski, Rundle-Thiele, & Beaumont, 2009). 

Para este trabajo, se realizará un análisis de la segmentación, a partir de la motivación del viaje (p.e: turismo de sol y playa, turismo cultural, …), del mercado turístico interno en España mediante la aplicación de un gran número de técnicas de aprendizaje supervisado, con el fin de encontrar aquellos modelos que obtengan unos mejores niveles de predicción. El análisis se llevará a cabo mediante el software estadístico R.

# 2. Data Wrangling

```{r Carga de datos}
df <- read_csv("~/Documents/Segmentacion-mercado-turistico/Dataset/data_turismo.csv")

# Solo año 2017
df %>% filter( anyo == 2017) -> df

# Codificación de variables categóricas
df$provdest <- as.factor(df$provdest)
df$transprin <- as.factor(df$transprin)
df$ccaa_residencia <- as.factor(df$ccaa_residencia)
df$motiv <- as.factor(df$motiv)
df$motiv <- factor(df$motiv)
df$alojaprin <- factor(df$alojaprin)
```

La base de datos utilizada en este proyecto proviene de los microdatos de la Encuesta de Turismo Residente publicada mensualmente por el INE desde 2015 (INE, 2019). Esta base de datos recopila información sobre una muestra representativa de familias españolas en viajes turísticos, entendiendo los viajes turísticos como todos aquellos viajes a un destino fuera del entorno habitual de residencia de la persona, que involucra al menos una pernoctación fuera del entorno mencionado y que tienen una duración inferior a un año.

Entre las variables incluidas en la base de datos (un total de 121) encontramos información sobre las regiones de origen y destino de cada viaje, el motivo del viaje (sol y playa, cultural, deportivo,…), el medio de transporte utilizado (coche, avión,…), el tipo de alojamiento en destino (hotel, apartamento, casa familiar,…), entre muchas otras variables.

También encontramos información sociodemográfica de los turistas como: edad, nivel educativo, o los ingresos familiares de. La base de datos contiene un total de 243,447 obseraciones desde 2015.  En 2017, el último año con datos no provisionales, la encuesta recopiló información sobre 67,953 viajes. 


Con el objetivo de perder el menor número de observaciones posibles, se descartan todas aquellas variables que tengan más de un 10% de observaciones faltantes (NA’s).

```{r Tratamiento de NA}
# Descartar aquellas columnas con más de un 10% de NA's
df <- df[, -which(colMeans(is.na(df)) > 0.1)]
```

Siguiendo una voluntad de replicabilidad en el ámbito no-académico, se han eliminado todas aquellas variables que contienen información “ex post” o que resultan irrelevantes para el estudio (p.e: identificadores). Por tanto, la selección final de variables tan solo incluye aquellas que pueden obtenerse de forma previa mediante el uso de “cookies” (p.e: provincia de origen) o la contestación a un cuestionario/formulario (p.e: actividades que le gustaría realizar, con quien tiene pensado viajar, etc.). 

También se han eliminado todas aquellas observaciones que presentan valores faltantes o NA's

```{r Limpieza}
# Eliminamos variables que no son de interes o están repetidas
df <- df[,-c(100)] # columna sobrante
df$paisdest <- NULL # no variación
df$destesp <- NULL # no variación
df$id <- NULL
df$anyo <- NULL
df$idsec <- NULL
df$bloque_etapas <- NULL
df$npernoc <- NULL
df$paquete <- NULL
df$impu_parcial <- NULL
df$gastofi_paq <- NULL
df$gasto_trans <- NULL
df$gasto_barest <- NULL
df$gasto_act <- NULL
df$gasto_aloja <- NULL
df$gasto_biendur <- NULL
df$gasto_resto <- NULL
df$igastofi_paq <- NULL
df$igastofi_act <- NULL
df$igastofi_aloja <- NULL
df$igastofi_barest <- NULL
df$igastofi_biendur <- NULL
df$igastofi_resto <- NULL
df$igastofi_total <- NULL
df$igastofi_trans <- NULL
df$factorgas_tot <- NULL
df$factorvi_15mas <- NULL
df$factorvi_tot <- NULL
df$miemv_15menos <- NULL
df$dest_costa <- NULL
df$dest_pen <- NULL
df$orden_rep <- NULL
df$orden_viaje <- NULL
df$ccaadest <- NULL
df$paisdest <- NULL
df$destesp <- NULL
df$gasto_paq <- NULL
df$gastofi_act <- NULL
df$gastofi_aloja <- NULL
df$gastofi_barest <- NULL
df$gastofi_biendur <- NULL
df$gastofi_resto <- NULL
df$gastofi_trans <- NULL
df$corr15_vt <- NULL
df$transprin <- NULL

# Eliminar NA's
df <- na.omit(df)

# Dataframe numerico
df.numeric <- data.matrix(df)
df.numeric <- na.omit(df.numeric)
```

La variable dependiente de nuestro análisis es la de “motivo de viaje”. En la siguiente tabla se presentan las 18 categorías que puede tomar dicha variable. 

```{r Tabla Motivaciones}
levels(df$motiv)
```

En el caso de realizar un estudio puramente teórico, se podrían utilizar todas las categorías incluidas en la encuesta. Sin embargo, debido a la naturaleza de este trabajo, no se han considerado todos aquellos viajes realizados por motivos cuya naturaleza no se puede atribuir exclusivamente a la voluntad del turista (p.e: identificar previamente a un turista cuya motivación es la de visitar a un familiar puede tener poco valor para una empresa que ofrezca servicios turísticos a la hora de realizar, por ejemplo, acciones de marketing on-line). 

Finalmente, se han considerado las 8 categorías expuestas en la siguiente tabla, dónde también se expone el peso relativo de cada una de ellas sobre el total de las observaciones consideradas.

```{r Reducir número de categorías}
df %>%
        filter(motiv != "Visita familiar") %>%
        filter(motiv != "Personal_Otros") %>%
        filter(motiv != "Centro trabajo") %>%
        filter(motiv != "Incentivos") %>%
        filter(motiv != "Salud") %>% 
        filter(motiv != "Congresos") %>% 
        filter(motiv != "Educacion") %>%
        filter(motiv != "Religioso") %>%
        filter(motiv != "Reuniones") -> df

df %>%
        group_by(motiv) %>%
        summarise(no_rows = (length(motiv)/nrow(df))*100)
```

Una vez realizado este tratamiento previo, la base de datos final consta de un total de `r count(df)` observaciones con un total de `length(df)` variables. 

# 3. Conjunto de entrenamiento y conjunto de prueba

En último lugar, se ha realizado una división del dataset con el objetivo de obtener un conjunto de entrenamiento (que se utilizará para entrenar los diferentes modelos) que contenga el 80% de las observaciones y un conjunto de prueba (con el que se evaluará el rendimiento de cada modelo) con el 20% de las observaciones no incluidas en el conjunto de entrenamiento. Este tipo de división se puede considerar estándar en la aplicación de técnicas de Aprendizaje Estadístico, tal y como señalan manuales de referencias como James, Witten, Hastie, & Tibshirani (2013).

```{r Train & Test Sample (Catools)}
set.seed(111)
library(caTools)
split = sample.split(df$motiv, SplitRatio = 0.8)
df.train = subset(df, split == TRUE)
df.test = subset(df, split == FALSE)
```

Finalmente, es importante señalar que para realizar esta división se ha utilizado la función split.sample del paquete `caTools`. Tal y como se señala en la documentación del paquete, dicha función: “divide los datos del vector Y en dos conjuntos en una relación predefinida mientras conserva las relaciones relativas de diferentes etiquetas en Y. Se utiliza para dividir los datos utilizados durante la clasificación en subconjuntos de entrenamiento y prueba.” (caTools, 2019). 

# 4. Aplicación de técnicas de Machine Learning

## 4.1 Métricas para la evaluación de modelos y “tuning”

· Debido a la naturaleza clasificatoria del problema analizado, se ha seleccionado el porcentaje de observaciones correctamente clasificadas como métrica para la evaluación y comparación de los distintos modelos de aprendizaje estadístico implementados.

· Finalmente, con el objetivo de realizar un buen “tuning” de los parámetros de cada uno de los modelos y evitar situaciones de sobreajuste, se utilizará el método de la Validación Cruzada con 5 o 10 “folds”.

## 4.2 Técnicas de Aprendizaje no-Supervisado

A pesar de que el objetivo principal del presente trabajo es la aplicación de técnicas de aprendizaje supervisado, también se aplicará un modelo de Análisis de Componentes Principales (en adelante, PCA). 

Al contar con un total de 57 variables, la aplicación de ciertos modelos de aprendizaje supervisado, como el KNN, puede implicar problemas relacionados con la “maldición de dimensión”. 

```{r PCA}
set.seed(111)
pr.out = prcomp(df.numeric, scale=TRUE)
pr.var=pr.out$sdev^2
pve=pr.var/sum(pr.var)
```

Como se puede comprobar, cada uno de los componentes explica un porcentaje pequeño de la varianza total. En concreto, el componente 1, el que más información contiene, tan solo explica el 8.4% de la varianza total.

```{r PCA Table1}
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", ylim=c(0,1),type='b')
```

En el segundo gráfico se ha representado el porcentaje acumulado de la varianza explicada por cada componente. A modo de ejemplo, los primeros 34 componentes principales explican el 80% de la varianza total. 

```{r PCA Table2}
plot(cumsum(pve), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", ylim=c(0,1),type='b')
```

Del análisis de este modelo se extrae que existe una baja correlación entre las variables incluidas en el modelo y, por tanto, la reducción del número de variables (dimensiones) podría conllevar una perdida considerable de información.


## 4.3 Técnicas de Aprendizaje Supervisado

### 4.3.a Método de los vecinos más cercanos (KNN)

El método de “vecinos mas cercanos” (en adelante KNN) resulta el modelo de clasificación básico y más intuitivo de entre todos los que se van a aplicar en este trabajo. Cada observación se clasifica en una categoría dependiendo de que categoría es la “dominante” entre sus K vecinos más cercanos.

```{r KNN: CV}
set.seed(111)
cv10 <- trainControl(method  = "cv", number  = 10)
knn.cv10 <- train(motiv ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = 1:10),
             trControl  = cv10,
             metric     = "Accuracy",
             data       = df.train)
knn.cv10
```

Como se puede comprobar en la tabla anterior, el mejor modelo se obtiene con K = 1, es decir, clasificando cada observación a partir de la categoría de su vecino más cercano. 

```{r Best KNN: K=1}
set.seed(111)
ind <- sample(2, nrow(df.numeric), replace=TRUE, prob=c(0.8, 0.2))
df.train.num <- df.numeric[ind==1, -c(3), drop = TRUE]
df.test.num <- df.numeric[ind==2, -c(3), drop = TRUE]
trainlabes <- df.numeric[ind==1, 3, drop = TRUE]
testlabels <- df.numeric[ind==2, 3, drop = TRUE]

knn.pred.1 <- knn(train = df.train.num, test = df.test.num, cl = trainlabes, k=1)

knn.accuracy.k1 = mean(knn.pred.1==testlabels)
```

Una vez seleccionado K = 1 se aplica el mismo modelo a los datos del conjunto de prueba, obteniéndose un porcentaje de observaciones correctamente clasificadas igual a `r round(knn.accuracy.k1,2)`.

Si lo comparamos el clasificador mas “ingenuo” posible (clasificar todas las observaciones como la categoría con mayor representación en la muestra), con el método de KNN con K=1 se obtiene una mejora de 4.56 puntos percentuales. Por tanto, este modelo supone una mejora desde el punto de partida.


### 4.3.b Regresión Logística

En segundo lugar, se ha estimado una regresión logística multinomial. Se ha utilizado el método de la validación cruzada (con 10 “folds”) para optimizar los parámetros de la regresión sobre el conjunto de entrenamiento. Una vez obtenidos estos parámetros se ha realizado una predicción para los valores del conjunto de prueba. 

```{r Multinomial Logit CV10}
set.seed(111)
glm.fit.cv10 <- multinom(motiv ~., data = df.train, MaxNWts = 100000, K = 10, maxit = 1000)
glm.preds.cv10 = predict(glm.fit.cv10, type="class", newdata = df.test)
logit.accuracy = mean(glm.preds.cv10==df.test$motiv)
```

Aplicando el modelo Logit con Validación Cruzada, tras 450 iteraciones, se ha obtenido un porcentaje de observaciones correctamente clasificadas igual a `r round(logit.accuracy,2)`. Esto supone un incremento de 10 puntos porcentuales sobre el clasificador KNN. 


### 4.3.c Análisis Discriminante Lineal (LDA)

El tercer modelo aplicado es el Análisis Discriminante Lineal (LDA) que, según la teoría, actúa mejor que el modelo Logístico cuando los datos están bien separado en clases y cuando se trabajan con más de dos clases. 

```{r Linear Discriminant Analysis}
lda.fit <- train(motiv ~ . -provdest,
             method     = "lda",
             trControl  = cv10,
             metric     = "Accuracy",
             data       = df.train)
lda.pred = predict(lda.fit, newdata = df.test)
table(lda.pred, df.test$motiv)
lda.accuracy = mean(lda.pred == df.test$motiv)
```

En la tabla superior se observa la matriz de confusión del modelo LDA. Estos resultados se traducen en una “accuracy” sobre el conjunto de prueba del `r round(lda.accuracy)`. Este resultado es sensiblemente inferior al obtenido por el modelo Logit por tanto, a diferencia de lo que indica la literatura, en este caso el modelo LDA tiene una menor capacidad de clasificación que el Logit a pesar de contar con 8 clases.

### 4.3.d Árbol de decisión


```{r Decision Tree}
set.seed(111)
tree.tourism = tree(motiv~. -provdest, data = df.train)
summary(tree.tourism)
plot(tree.tourism); text(tree.tourism, pretty = 0)
tree.pred = predict(tree.tourism, df.test, type = "class")
with(df.test, table(tree.pred, motiv))
tree.accuracy = mean(tree.pred==df.test$motiv)
tree.accuracy
```

```{r Decision Tree: CV to prune}
tree.cv.tourism = cv.tree(tree.tourism, FUN= prune.misclass)
plot(tree.cv.tourism)
prune.tourism = prune.misclass(tree.tourism, best = 5)
plot(prune.tourism); text(prune.tourism, pretty = 0)
tree.pred.cv = predict(prune.tourism, df.test, type="class")
with(df.test, table(tree.pred.cv, motiv))
tree.accuracy.cv = mean(tree.pred.cv==df.test$motiv)
tree.accuracy.cv
```

```{r Random Forest}
set.seed(111)
# 60% Training, 20% Validation, 20% Test 
inTraining <- createDataPartition(df.train$motiv, p=0.75, list=FALSE)
training.set <- df.train[inTraining,]
validation.set <- df.train[-inTraining,]

dataset <- training.set
validation <- validation.set
test <- df.test
# The final model will actually use all data, except test
total <- rbind(dataset, validation)

# Reduce the grid to save time here. 
fitControl <- trainControl(method = 'cv', number = 5, summaryFunction=defaultSummary)

rfGrid <-  expand.grid(mtry = c(1,3, 5,7,9))

### Random Forest algorithm. ###
fit.rf <- train(motiv~., data=dataset, method = 'rf', trControl=fitControl, tuneGrid=rfGrid, metric='Accuracy', distribution='multinomial')
fit.rf
plot(fit.rf)
res_rf <- fit.rf$results
acc_rf <- subset(res_rf[2])
# CV con mejor "tune"
max(acc_rf)

rf.caret.pred <- predict(fit.rf,validation)

table(rf.caret.pred ,validation$motiv)
mean(rf.caret.pred==validation$motiv)

fit.rf_total <- train(motiv~., data=total, method = 'rf', trControl=fitControl, tuneGrid=rfGrid, metric='Accuracy', distribution='multinomial')
fit.rf_total
plot(fit.rf_total)
res_rf_total <- fit.rf_total$results
acc_rf_total <- subset(res_rf_total[2]) 
# CV con mejor "tune" 
max(acc_rf_total)
#Evaluate on test
rf.caret.pred_total <- predict(fit.rf_total,test)

table(rf.caret.pred_total ,test$motiv)
rf.accuracy = mean(rf.caret.pred_total==test$motiv)
```



```{r Boosting CV}
set.seed(111)
#PREPARE A GRID. NOTE: All combinations will be evaluated!
gbmGrid <-  expand.grid(interaction.depth = c(2,4,6),
                        n.trees = c(100, 200, 500),
                        shrinkage = c(.001, .01),
                        n.minobsinnode = 10)

fitControl <- trainControl(method = 'cv', number = 5, summaryFunction=defaultSummary)

### Gradient boosting machine algorithm. ###
fit.gbm <- train(motiv~., data=dataset, method = 'gbm', trControl=fitControl, tuneGrid=gbmGrid, metric='Accuracy', distribution='multinomial')
fit.gbm
plot(fit.gbm)
fit.gbm$bestTune

res_gbm <- fit.gbm$results
acc_gbm <- subset(res_gbm[5])
# CV con mejor "tune"
max(acc_gbm)

boost.caret.pred <- predict(fit.gbm,validation)
table(boost.caret.pred ,validation$motiv)
mean(boost.caret.pred==validation$motiv)

fit.gbm_total <- train(motiv~., data=total, method = 'gbm', trControl=fitControl, tuneGrid=gbmGrid, metric='Accuracy', distribution='multinomial')
fit.gbm_total
plot(fit.gbm_total)
fit.gbm_total$bestTune

res_gbm_total <- fit.gbm_total$results
acc_gbm_total <- subset(res_gbm_total[5])
# CV con mejor "tune"
max(acc_gbm_total)

#Evaluate on test
boost.caret.pred_total <- predict(fit.gbm_total,test)

table(boost.caret.pred_total ,test$motiv)
bgm.accuracy = mean(boost.caret.pred_total==test$motiv)
summary(fit.gbm_total, n.trees=500)
```

```{r Resumen}
table(knn.accuracy.k1, logit.accuracy, lda.accuracy, tree.accuracy, tree.accuracy.cv, rf.accuracy, bgm.accuracy)
```

